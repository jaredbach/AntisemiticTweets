{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean & Segment Tweets Using the Ekphrasis Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AmiBach/Desktop/Programming/AntisemiticTweets/venv/lib/python3.9/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    \n",
    "    # Terms to be Normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user','time', 'url', 'date', 'number'],\n",
    "    \n",
    "    # Fix HTML Tokens\n",
    "    fix_html=True, \n",
    "    \n",
    "    # Corpus from Which the Word Statistics are to be Used \n",
    "    ### For Word Segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # Corpus from Which the Word Statistics are to be Used \n",
    "    ### For Spell Correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    # Perform Word Segmentation on Hashtags\n",
    "    unpack_hashtags=True,\n",
    "    \n",
    "    # Unpack Contractions\n",
    "    unpack_contractions=True,\n",
    "    \n",
    "    # Spell Correction for Elongated Words\n",
    "    spell_correct_elong=True,\n",
    "    \n",
    "    # List of Dicts, for Replacing Tokens Extracted from Text,\n",
    "    ### With other Expressions. Can Pass More than One Dict.\n",
    "    dicts=[emoticons]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and Load CSV\n",
    "tweets = pd.read_csv(\"Tweets.csv\")\n",
    "\n",
    "# Apply Ekphrasis to Tweets Content Column\n",
    "tweets['content'] = tweets['content'].transform(lambda tweet: text_processor.pre_process_doc(tweet))\n",
    "\n",
    "# Export to New CSV\n",
    "tweets.to_csv('Ekphrasis_Tweets.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
